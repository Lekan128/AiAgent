###AI Agent Core Library
Welcome to the AI Agent Core Library! This library provides a robust, reflection-based framework for integrating Language Models (LLMs) with custom Java methods (Tools), allowing the LLM to execute code to fulfill complex user requests.

The library uses a three-stage process: Planning (LLM determines needed tools), Execution (Java reflects and runs tools), and Response (LLM uses tool results to generate final structured output).

1. Prerequisites
Before starting, ensure you have:

Java 17+

A concrete LLM implementation (e.g., the included Gemini class or a custom subclass).

Jackson Annotations (@JsonProperty, etc.) for structured response classes.

2. Core Concepts
A. The Agent
The central component is the {@code Agent}, which orchestrates the workflow. You should always retrieve the singleton instance via the provider:

import com.yourpackage.Agent;
import com.yourpackage.AgentProvider;

Agent agent = AgentProvider.get();

B. The LLM Abstraction
All Language Models must implement the {@code LLM} abstract class.

To use a new LLM (e.g., a custom local model or Azure OpenAI), you must subclass {@code LLM}.

// Example of a custom LLM implementation
public class CustomLLM extends LLM {

    @Override
    public String getModelName() {
        return "Custom-Local-Model-V1";
    }

    @Override
    public String call(String prompt) {
        // Implement API call logic here (e.g., HTTP request)
        String rawLLMResponse = sendApiRequest(prompt);
        return rawLLMResponse;
    }
}

3. Tool Definition and Usage (Function Calling)
The library uses custom annotations for defining Java methods that the LLM can "call."

A. Defining the Tool Method
Annotate any static or instance method you want the LLM to access using @AiToolMethod. The value must be a detailed description of what the method does and what it returns.

import com.yourpackage.AiToolMethod;
import com.yourpackage.ArgDesc;
import com.fasterxml.jackson.core.JsonProcessingException;
import java.util.List;

public class InventoryTools {

    /**
     * Finds and returns a list of product objects that match the specified search query.
     * Returns a JSON list of Product objects, each containing ID, name, and price.
     */
    @AiToolMethod("Searches the product inventory using a query and returns a list of matching Product details.")
    public static List<Product> searchInventory(
        @ArgDesc("The short search query or product name to look up.")
        String query,

        @ArgDesc("The maximum number of results to return (e.g., 5, 10).")
        int limit
    ) {
        // Implementation logic here
        return findProducts(query, limit);
    }
}

B. Defining Tool Method Arguments
Each parameter in an @AiToolMethod must be annotated with @ArgDesc. This description is crucial as the LLM uses it to determine what value to generate for that argument.

4. Executing the Agent
To execute a request, you need to provide the query, a persona, the LLM instance, and the class you want the response to be mapped into.

import com.yourpackage.AgentProvider;
import com.yourpackage.LLM;

// 1. Define your desired response structure (must be a Java class)
public class FinalSummary {
    public String analysis;
    public List<String> sourcesUsed;
}

public void runAgent() throws Exception {
    Agent agent = AgentProvider.get();
    LLM geminiLLM = new Gemini(); // Or your CustomLLM instance

    String userQuery = "I need a summary of all inventory items found for 'laptop' and their combined price.";
    String aiPersona = "A meticulous inventory analyst who prioritizes accuracy.";

    // 2. Execute the agent call
    FinalSummary result = agent.useAgent(
        userQuery,
        aiPersona,
        geminiLLM,
        FinalSummary.class // Target structured class
    );

    System.out.println("Analysis: " + result.analysis);
}

Internal Components (For Developers)
The following classes are for internal library use only and are subject to change. They handle the mechanics of reflection and data serialization:

ObjectMapperSingleton: Provides the configured Jackson mapper used for serializing tool schemas and deserializing structured responses.

MethodDescriptor: Utility used to convert annotated Java methods into {@code MethodDescription} DTOs.

ReflectionCaller: Executes the pipeline of LLM-planned method calls using reflection.

MethodDescription, ReflectionInvocableMethod, MethodArgument: Internal DTOs used for representing method metadata and execution requests